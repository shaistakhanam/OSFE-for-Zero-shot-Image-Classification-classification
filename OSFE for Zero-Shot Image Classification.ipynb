{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00add116",
      "metadata": {
        "id": "00add116"
      },
      "source": [
        "# Classification Report with GLCM and BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bde7b85a",
      "metadata": {
        "id": "bde7b85a"
      },
      "source": [
        "## Create and Save CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9d47c80",
      "metadata": {
        "id": "d9d47c80"
      },
      "outputs": [],
      "source": [
        "# Import library \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.applications import ResNet50\n",
        "\n",
        "from skimage.feature import greycomatrix, greycoprops\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from gensim.utils import simple_preprocess\n",
        "import os, re\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# lib's\n",
        "from pickle import dump , load\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import keras\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense, Concatenate, Flatten\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import h5py\n",
        "\n",
        "import glob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d25ff53d",
      "metadata": {
        "id": "d25ff53d"
      },
      "outputs": [],
      "source": [
        "# function\n",
        "# Function to extract visual features using ResNet50\n",
        "def extract_visual_features(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize((224, 224))  # Resize image for ResNet50 input\n",
        "    img_array = np.array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array = tf.keras.applications.resnet50.preprocess_input(img_array)\n",
        "\n",
        "    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
        "    visual_features = model.predict(img_array, verbose = 0)\n",
        "\n",
        "    return visual_features\n",
        "\n",
        "# Function to compute GLCM texture features\n",
        "def compute_texture_features(image_path):\n",
        "    # Define your GLCM properties (distances and angles)\n",
        "    distances = [1, 3, 5, 3, 1, 3, 5]\n",
        "    angles = [0, 0, 0, np.pi/4, np.pi/2, np.pi/2, np.pi/2]\n",
        "\n",
        "    glcm_features = []\n",
        "    for distance, angle in zip(distances, angles):\n",
        "        img_gray = Image.open(image_path).convert('L')  # Convert image to grayscale\n",
        "        img_gray_array = np.array(img_gray)\n",
        "\n",
        "        # Compute GLCM properties\n",
        "        glcm = greycomatrix(img_gray_array, distances=[distance], angles=[angle], levels=256, symmetric=True, normed=True)\n",
        "        contrast = greycoprops(glcm, 'contrast')[0, 0]\n",
        "        dissimilarity = greycoprops(glcm, 'dissimilarity')[0, 0]\n",
        "        homogeneity = greycoprops(glcm, 'homogeneity')[0, 0]\n",
        "        energy = greycoprops(glcm, 'energy')[0, 0]\n",
        "        correlation = greycoprops(glcm, 'correlation')[0, 0]\n",
        "\n",
        "\n",
        "\n",
        "        glcm_features.extend([contrast, dissimilarity, homogeneity, energy, correlation])\n",
        "\n",
        "    return np.array(glcm_features) # np.array([contrast, dissimilarity, homogeneity, energy, correlation])\n",
        "\n",
        "# Load image data and compute features\n",
        "def load_data_and_compute_features(data_dir):\n",
        "    visual_features = []\n",
        "    texture_features = []\n",
        "    labels = []\n",
        "\n",
        "    classes = os.listdir(data_dir)\n",
        "    class_to_index = {cls: idx for idx, cls in enumerate(classes)}\n",
        "    # print(f\"classes : {classes} \\nclass_to_index : {class_to_index}\")\n",
        "\n",
        "    for cls in tqdm(classes, desc=\"Processing images\"):\n",
        "        cls_dir = os.path.join(data_dir, cls)\n",
        "\n",
        "        for img_name in os.listdir(cls_dir):\n",
        "            img_path = os.path.join(cls_dir, img_name)\n",
        "\n",
        "            # Extract visual features using ResNet50\n",
        "            visual_feat = extract_visual_features(img_path)\n",
        "            visual_features.append(visual_feat)\n",
        "            # print(f\"visual_features : {visual_features}\")\n",
        "\n",
        "            # Compute texture features using GLCM\n",
        "            texture_feat = compute_texture_features(img_path)\n",
        "            texture_features.append(texture_feat)\n",
        "            # print(f\"texture_features : {texture_features}\")\n",
        "\n",
        "            # Assign label index\n",
        "            labels.append(class_to_index[cls])\n",
        "            # print(f\"img_path : {img_path} || labels : {class_to_index[cls]} \\n\")\n",
        "            # print(f\"texture_features : {texture_feat} \\n\")\n",
        "\n",
        "    visual_features = np.array(visual_features)\n",
        "    texture_features = np.array(texture_features)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return visual_features, texture_features, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "667611fa",
      "metadata": {
        "id": "667611fa",
        "outputId": "1494114a-9d7c-420d-daab-308e4b8a833f",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# load_data_and_compute_features\n",
        "data_directory = 'dataset path'\n",
        "visual_features, texture_features, labels = load_data_and_compute_features(data_directory)\n",
        "print('Done')\n",
        "print(visual_features.shape, texture_features.shape, labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be15cc61",
      "metadata": {
        "id": "be15cc61"
      },
      "outputs": [],
      "source": [
        "data_vt = pd.DataFrame(np.concatenate([visual_features.reshape(visual_features.shape[0], -1), texture_features], axis=1))\n",
        "data_vt['labels'] = labels\n",
        "\n",
        "data_vt.to_csv('dataset_features.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa16be9c",
      "metadata": {
        "id": "aa16be9c"
      },
      "source": [
        "# ---------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf9986fd",
      "metadata": {
        "id": "cf9986fd"
      },
      "source": [
        "## Model Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5f62aa1",
      "metadata": {
        "id": "e5f62aa1"
      },
      "outputs": [],
      "source": [
        "# Variable's\n",
        "min_max_scaler_file = 'min_max_scaler.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f94c80ca",
      "metadata": {
        "id": "f94c80ca"
      },
      "outputs": [],
      "source": [
        "# Function\n",
        "# Build and train a classification model\n",
        "def build_and_train_model(visual_features, texture_features, labels):\n",
        "    # Concatenate visual and texture features\n",
        "    combined_features = np.concatenate([visual_features,\n",
        "                                        texture_features],\n",
        "                                       axis=1)\n",
        "\n",
        "\n",
        "    # Normalize the features\n",
        "    min_max_scaler = StandardScaler()\n",
        "    train_normalized_texture_features = min_max_scaler.fit_transform(combined_features)\n",
        "    train_normalized_texture_features_df = pd.DataFrame(train_normalized_texture_features)\n",
        "\n",
        "    # save\n",
        "    dump(min_max_scaler, open(min_max_scaler_file, 'wb'))\n",
        "\n",
        "    # Split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(train_normalized_texture_features_df,\n",
        "                                                        labels,\n",
        "                                                        test_size=0.3,\n",
        "                                                        random_state=42,\n",
        "                                                        stratify=labels)\n",
        "\n",
        "    # Define classification model\n",
        "    input_layer = Input(shape=(combined_features.shape[1],))\n",
        "    hidden_layer = Dense(128, activation='relu')(input_layer)\n",
        "    output_layer = Dense(len(np.unique(labels)), activation='softmax')(hidden_layer)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.summary()\n",
        "    model.compile(optimizer=Adam(lr=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        epochs=100,\n",
        "                        batch_size=64,\n",
        "                        validation_data=(X_test, y_test))\n",
        "\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(1, len(acc)+1)\n",
        "\n",
        "    plt.plot(epochs, acc, label='training accuracy')\n",
        "    plt.plot(epochs, val_acc, label='validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Training validation Accuracy')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(epochs, loss, label='training loss')\n",
        "    plt.plot(epochs, val_loss, label='validation loss')\n",
        "    plt.legend()\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.title('Training validation Loss')\n",
        "    plt.show()\n",
        "\n",
        "    return model # history # model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bef7854",
      "metadata": {
        "id": "8bef7854"
      },
      "outputs": [],
      "source": [
        "# load csv\n",
        "data_vtl = pd.read_csv('dataset_features.csv')\n",
        "visual_features, texture_features, labels = data_vtl.iloc[:,:2048], data_vtl.iloc[:,2048:-1], data_vtl.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d61704a",
      "metadata": {
        "id": "2d61704a",
        "outputId": "bc1cd975-e81d-44e2-d3f1-1fe8ae75b1d7"
      },
      "outputs": [],
      "source": [
        "# Build and train the classification model\n",
        "classification_model = build_and_train_model(visual_features, texture_features, labels)\n",
        "classification_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edfcfaae",
      "metadata": {
        "id": "edfcfaae",
        "outputId": "b6141409-8b0d-419a-f4a8-8e5fc7694fd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "# save model and architecture to single file\n",
        "classification_model.save(\"OSFE_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f3d69f1",
      "metadata": {
        "id": "2f3d69f1"
      },
      "source": [
        "# -------------------------------------------------------------------------------------\n",
        "\n",
        "## Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b80320a7",
      "metadata": {
        "id": "b80320a7"
      },
      "outputs": [],
      "source": [
        "# Load models\n",
        "classification_model = load_model('OSFE_model.h5')\n",
        "min_max_scaler_model = load(open('min_max_scaler.pkl', 'rb'))\n",
        "class_labels = ['add class labels of training and zero-shot classes']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aa6a7d3",
      "metadata": {
        "id": "6aa6a7d3"
      },
      "source": [
        "### CR without BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fea5eb2",
      "metadata": {
        "id": "2fea5eb2",
        "outputId": "3862ceac-c0a7-4280-e5b0-ca947915ba35",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "image_path, image_label, pred_image_label, act_label, pred_label = [], [], [], [], []\n",
        "\n",
        "for img_path in glob.glob(r\"test_datapath/*/*\"):\n",
        "#     print(f\"img_path : {img_path}\")\n",
        "    image_path.append(img_path)\n",
        "    image_label.append(img_path.split('\\\\')[-2])\n",
        "    act_label.append(class_labels.index(img_path.split('\\\\')[-2]))\n",
        "\n",
        "    # Extract visual features using ResNet50\n",
        "    visual_features = extract_visual_features(img_path)\n",
        "#     print(f\"visual_features : {visual_features.shape} || {type(visual_features)}\")\n",
        "\n",
        "    # Compute texture features using GLCM\n",
        "    texture_features = compute_texture_features(img_path)\n",
        "#     print(f\"texture_feat : {texture_features.shape} || {type(texture_features)}\")\n",
        "\n",
        "    # Concatenate visual and texture features\n",
        "    l1 = visual_features[0].tolist()\n",
        "    l2 = texture_features.tolist()\n",
        "    l1.extend(l2)\n",
        "    combined_features = np.array(l1)\n",
        "#     print(f\"combined_features : {combined_features}\")\n",
        "\n",
        "    # Normalize the features\n",
        "    train_normalized_texture_features = min_max_scaler_model.transform([combined_features])\n",
        "    train_normalized_texture_features_df = pd.DataFrame(train_normalized_texture_features)\n",
        "#     print(f\"train_normalized_texture_features_df : {train_normalized_texture_features_df}\")\n",
        "\n",
        "#     model.predict\n",
        "    predicted_value = classification_model.predict(train_normalized_texture_features_df, verbose = 0)\n",
        "#     print(f\"predicted_value : {np.argmax(predicted_value)} || {class_labels[np.argmax(predicted_value)]}\")\n",
        "    pred_image_label.append(class_labels[np.argmax(predicted_value)])\n",
        "    pred_label.append(np.argmax(predicted_value))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63b28876",
      "metadata": {
        "id": "63b28876"
      },
      "source": [
        "### CR with BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6yT6v6O-4Jyd",
      "metadata": {
        "id": "6yT6v6O-4Jyd"
      },
      "source": [
        "#Classification with NLP Autoencoder#\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jib8RN9R7aiH",
      "metadata": {
        "id": "Jib8RN9R7aiH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "# Define the model folder path\n",
        "model_folder_path = 'add model folder path'\n",
        "\n",
        "# Load the encoder model\n",
        "encoder_model_path = os.path.join(model_folder_path, 'add path of encoder model file')\n",
        "encoder = load_model(encoder_model_path)\n",
        "\n",
        "# Load the autoencoder model\n",
        "autoencoder_model_path = os.path.join(model_folder_path, 'add path of autoencoder model file')\n",
        "autoencoder = load_model(autoencoder_model_path)\n",
        "\n",
        "print(\"Models loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "RGJ2OIbrCd7x",
      "metadata": {
        "id": "RGJ2OIbrCd7x"
      },
      "outputs": [],
      "source": [
        "def find_similar_sentences(target_sentence_index, sentence_to_latent, top_n=10):\n",
        "    target_latent = sentence_to_latent[target_sentence_index]\n",
        "    similarities = []\n",
        "    for index, latent in sentence_to_latent.items():\n",
        "        if index != target_sentence_index:\n",
        "            similarity = 1 - cosine(target_latent, latent)\n",
        "            similarities.append((index, similarity))\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    return similarities[:top_n]\n",
        "\n",
        "def predict_with_autoencoder(input_word_index, sentence_to_latent, top_n=5):\n",
        "    # Find sentences similar to the first sentence\n",
        "    similar_sentences = find_similar_sentences(input_word_index, sentence_to_latent, top_n=top_n)\n",
        "    similar_words = [custom_sentences[index] for index, score in similar_sentences]\n",
        "    return similar_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98e81018",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example custom dataset\n",
        "custom_sentences = ['add labels of training and zero shot classes']\n",
        "\n",
        "# animals_list_file_path = os.path.join('..', 'Dataset', 'artefact1', 'animals.txt')\n",
        "# with open(animals_list_file_path, \"r\") as f:\n",
        "#custom_sentences = [line[:-1] for line in f]\n",
        "\n",
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(file_path):\n",
        "    embeddings_index = {}\n",
        "    with open(file_path, 'r', encoding='utf8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    return embeddings_index\n",
        "\n",
        "embeddings_index = load_glove_embeddings(r\"D:\\ZSL\\CNN\\glove.6B\\glove.6B.300d.txt\")  # Using 50d GloVe embeddings\n",
        "print(f\"embeddings_index : {type(embeddings_index)} \\n\")\n",
        "\n",
        "# Convert sentences to embeddings\n",
        "def sentence_to_embedding(sentence, embeddings_index):\n",
        "    words = simple_preprocess(sentence)\n",
        "    valid_words = [embeddings_index[word] for word in words if word in embeddings_index]\n",
        "    if valid_words:\n",
        "        return np.mean(valid_words, axis=0)\n",
        "    else:\n",
        "        return np.zeros(300) # Using 50d GloVe embeddings\n",
        "\n",
        "sentence_embeddings = np.array([sentence_to_embedding(sentence, embeddings_index) for sentence in custom_sentences])\n",
        "print(f\"sentence_embeddings : {type(sentence_embeddings)} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0TxyLQhl2rBd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TxyLQhl2rBd",
        "outputId": "15224368-110b-4bc5-8ee8-c57a81dde046"
      },
      "outputs": [],
      "source": [
        "# Encode sentences to get their latent representations\n",
        "sentence_latents = encoder.predict(sentence_embeddings)\n",
        "# print(f\"sentence_latents : {sentence_latents}\")\n",
        "\n",
        "# Create a dictionary to map sentences to their latent representations\n",
        "sentence_to_latent = {i: sentence_latents[i] for i in range(len(custom_sentences))}\n",
        "print(f\"sentence_to_latent : {sentence_to_latent}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd34a2e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dd34a2e7",
        "outputId": "a0de8530-8862-4080-9a0d-39b92182b78a"
      },
      "outputs": [],
      "source": [
        "\n",
        "j=0\n",
        "counter_rat=0\n",
        "counter_pig=0\n",
        "counter_raccoon=0\n",
        "counter_cat=0\n",
        "counter_leopard=0\n",
        "counter_humpback=0\n",
        "counter_hippopotamus=0\n",
        "counter_panda=0\n",
        "counter_chimp=0\n",
        "counter_seal=0\n",
        "\n",
        "Autoencoder_counter=0\n",
        "\n",
        "\n",
        "# Load models\n",
        "classification_model = load_model('OSFE_model.h5')\n",
        "min_max_scaler_model = load(open('min_max_scaler.pkl', 'rb'))\n",
        "class_labels = ['add class labels of training and zero-shot classes']\n",
        "\n",
        "\n",
        "\n",
        "image_path, image_label, pred_image_label, act_label, pred_label, similar_words = [], [], [], [], [], []\n",
        "\n",
        "\n",
        "# for img_path in glob.glob(folder_path):\n",
        "for img_path in glob.glob(r\"Path of test classes\\*\\*\"):\n",
        "    \n",
        "    \n",
        "    print(f\"img_path : {img_path}\")\n",
        "    image_path.append(img_path)\n",
        "    image_label.append(img_path.split('\\\\')[-2])\n",
        "    act_label.append(class_labels.index(img_path.split('\\\\')[-2]))\n",
        "\n",
        "    # Extract visual features using ResNet50\n",
        "    visual_features = extract_visual_features(img_path)\n",
        "\n",
        "\n",
        "    # Compute texture features using GLCM\n",
        "    texture_features = compute_texture_features(img_path)\n",
        "\n",
        "\n",
        "    # Concatenate visual and texture features\n",
        "    l1 = visual_features[0].tolist()\n",
        "    l2 = texture_features.tolist()\n",
        "    l1.extend(l2)\n",
        "    combined_features = np.array(l1)\n",
        "\n",
        "\n",
        "    # Normalize the features\n",
        "    train_normalized_texture_features = min_max_scaler_model.transform([combined_features])\n",
        "    train_normalized_texture_features_df = pd.DataFrame(train_normalized_texture_features)\n",
        "\n",
        "\n",
        "#     model.predict\n",
        "    predicted_value = classification_model.predict(train_normalized_texture_features_df)\n",
        "    print(f\"predicted_value : {np.argmax(predicted_value)} || {class_labels[np.argmax(predicted_value)]}\")\n",
        "    pred_image_label.append(class_labels[np.argmax(predicted_value)])\n",
        "    pred_label.append(np.argmax(predicted_value))\n",
        "\n",
        "    # Get the predicted label\n",
        "    predicted_class_label = class_labels[np.argmax(predicted_value)]\n",
        "    # print(predicted_class_label)\n",
        "\n",
        "  \n",
        "    if predicted_class_label in custom_sentences:\n",
        "        similar_words_autoencoder = predict_with_autoencoder(custom_sentences.index(predicted_class_label), sentence_to_latent, top_n=5)\n",
        "    else:\n",
        "        print(f\"Label {predicted_class_label} not found in custom_sentences.\")\n",
        "\n",
        "\n",
        "\n",
        "    similar_words_autoencoder = predict_with_autoencoder(custom_sentences.index(predicted_class_label), sentence_to_latent, top_n=10) # class_labels\n",
        "    print(f\"similar_words_autoencoder : {similar_words_autoencoder}\")\n",
        "\n",
        "\n",
        "    for i in similar_words_autoencoder:\n",
        "                 if (img_path.split(\"\\\\\")[-2]) in i:  \n",
        "                      Autoencoder_counter += 1\n",
        "                      print(img_path.split(\"\\\\\")[-2])\n",
        "\n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "shafin",
      "language": "python",
      "name": "shafin"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
